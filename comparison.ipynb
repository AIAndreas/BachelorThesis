{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import soundfile\n",
    "import librosa\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import soundfile as sf\n",
    "import speech_recognition as sound_rec\n",
    "from utils import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data/audioMNIST/data_OG_trimmed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set directories\u001b[39;00m\n\u001b[0;32m      2\u001b[0m audio_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/audioMNIST/data_OG_trimmed\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m wav_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      6\u001b[0m recon_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_mat/reconstructed_results\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data/audioMNIST/data_OG_trimmed'"
     ]
    }
   ],
   "source": [
    "# Set directories\n",
    "audio_dir = 'data/audioMNIST/data_OG_trimmed'\n",
    "files = os.listdir(audio_dir)\n",
    "wav_files = [f for f in files if f.endswith('.wav')]\n",
    "\n",
    "recon_dir = 'results_mat/reconstructed_results'\n",
    "recon_files = os.listdir(recon_dir)\n",
    "recon_wav_files = [f for f in recon_files if f.endswith('.wav')]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and create time domain plots  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OG\n",
    "\n",
    "# Define paths\n",
    "audio_dir = audio_dir  # Replace with the path to your reconstructed files\n",
    "output_dir = \"comparison/time_OG/\"\n",
    "\n",
    "# Clean the output directory before saving new plots\n",
    "if os.path.exists(output_dir):\n",
    "    # Remove all files in the output directory\n",
    "    for file in os.listdir(output_dir):\n",
    "        file_path = os.path.join(output_dir, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting file {file_path}: {e}\")\n",
    "else:\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Get a list of all files in the folder_path\n",
    "all_files = os.listdir(audio_dir)\n",
    "\n",
    "# Process each file in the reconstruction directory\n",
    "for file in all_files:\n",
    "\n",
    "    file_path = os.path.join(audio_dir, file)\n",
    "    \n",
    "    # Load the audio data\n",
    "    sr , _ = wavfile.read(file_path)\n",
    "    y, sr = librosa.load(file_path, sr = sr)\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure()\n",
    "    plt.plot(y)\n",
    "    plt.title(f\"{file} (Original)\")\n",
    "    plt.xlabel('Time (samples)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    \n",
    "    # Set the y-axis limits to -0.35 to 0.35\n",
    "    plt.ylim([-0.35, 0.35])\n",
    "    \n",
    "    # Save the plot to the specified folder\n",
    "    plot_path = os.path.join(output_dir, f\"{file}.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()  # Close the figure to free up memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path containing your audio files\n",
    "folder_path = 'results_mat/reconstructed_results'  # Replace with the path to your audio files\n",
    "output_dir = \"comparison/time_recon/\"\n",
    "\n",
    "# Clean the output directory before saving new plots\n",
    "if os.path.exists(output_dir):\n",
    "    # Remove all files in the output directory\n",
    "    for file in os.listdir(output_dir):\n",
    "        file_path = os.path.join(output_dir, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting file {file_path}: {e}\")\n",
    "else:\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Get a list of all files in the folder_path\n",
    "all_files = os.listdir(folder_path)\n",
    "\n",
    "# Loop through each file and generate a plot\n",
    "for file in all_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    \n",
    "    # Read the sample rate using scipy\n",
    "    sr, _ = wavfile.read(file_path)\n",
    "    \n",
    "    # Load the audio data using librosa with the original sample rate\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "    \n",
    "    # Create a time axis in samples\n",
    "    time_samples = np.arange(len(y))\n",
    "    \n",
    "    # Create a plot\n",
    "    plt.figure()\n",
    "    plt.plot(time_samples, y)\n",
    "    plt.title(f\"{file.replace('.npy', '')} (Reconstructed)\")\n",
    "    plt.xlabel('Time (samples)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    \n",
    "    # Set the y-axis limits to -0.35 to 0.35\n",
    "    plt.ylim([-0.35, 0.35])\n",
    "\n",
    "    # Save the plot to the specified folder\n",
    "    plot_path = os.path.join(output_dir, f\"{file.replace('.npy', '')}.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()  # Close the figure to free up memory\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrograms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_signal(S, max_length):\n",
    "    dif_sample = abs(len(S) - max_length) # Calculate the differnce in desired signal length and the current signal length\n",
    "\n",
    "    if len(S) % 2 != 0:\n",
    "        padded_y = np.pad(S, (dif_sample//2, dif_sample//2 + 1), 'constant', constant_values=(0, 0))\n",
    "    else:\n",
    "        padded_y = np.pad(S, (dif_sample//2, dif_sample//2), 'constant', constant_values=(0, 0))\n",
    "\n",
    "    return padded_y\n",
    "\n",
    "def load_data(folder_path):\n",
    "    # Get a list of all files in the folder_path\n",
    "    all_files = os.listdir(folder_path)\n",
    "\n",
    "    # Determine samplerate of signal\n",
    "    sr , _ = wavfile.read(folder_path + \"/\" + all_files[0])\n",
    "\n",
    "    audio_data = []\n",
    "    # Load the audio files\n",
    "    for file in all_files:\n",
    "        if file.endswith('.wav'):\n",
    "            y = librosa.load(folder_path + \"/\" + file, sr=sr)[0]\n",
    "            audio_data.append((y,file))\n",
    "\n",
    "    return audio_data\n",
    "\n",
    "def trim_signals(data, max_db):\n",
    "    trimmed_audio = []\n",
    "    for y, file in data:\n",
    "        if len(y) > 8000:\n",
    "            continue # Skip audio files longer than 8000 samples\n",
    "        y_trimmed, _ = librosa.effects.trim(y, ref=np.mean , top_db=10)\n",
    "        trimmed_audio.append((y_trimmed, file))\n",
    "    return trimmed_audio\n",
    "\n",
    "def pad_segment(s, window_size):\n",
    "    dif_sample = abs(len(s) - window_size) # Calculate the differnce in desired signal length and the current signal length\n",
    "    if len(s) % 2 != 0:\n",
    "        padded_y = np.pad(s, (dif_sample//2, dif_sample//2 + 1), 'constant', constant_values=(0, 0))\n",
    "    else:\n",
    "        padded_y = np.pad(s, (dif_sample//2, dif_sample//2), 'constant', constant_values=(0, 0))\n",
    "    return padded_y\n",
    "\n",
    "def stft(x, frame_size=256, overlap=128):\n",
    "    num_segments = len(x) // overlap - 1 # Calculate the numbxer of segments\n",
    "    freq_bins = frame_size // 2 + 1 # Define the number of frequency bins\n",
    "    spec = np.zeros((freq_bins, num_segments))\n",
    "    t = 0\n",
    "    for i in range(0, len(x)-frame_size, overlap):\n",
    "        seg = x[i:i+frame_size]\n",
    "        seg = np.hamming(len(seg)) * seg # Apply the hamming window\n",
    "        if len(seg) < frame_size: # if the segment is shorter than the window size, we need to pad it (usually the last segment)\n",
    "            seg = pad_segment(seg, frame_size)\n",
    "        spec[:,t] = np.abs(np.fft.rfft(seg, n=frame_size)) #Compute the magnitude of frequency components\n",
    "        t += 1\n",
    "    return spec\n",
    "\n",
    "def gen_spectgrams(audio_data, padding_length, n_fft=128):\n",
    "    # Compute the mel spectrogram\n",
    "    spects = []\n",
    "    for audio in audio_data:\n",
    "        if len(audio[0]) > 8000:\n",
    "            continue # Skip audio files longer than 8000 samples\n",
    "        y_trimmed, _ = librosa.effects.trim(audio[0], ref=np.mean , top_db=10)\n",
    "        padded_y = pad_signal(y_trimmed, padding_length)\n",
    "        spec = stft(padded_y, frame_size=n_fft, overlap=n_fft//2)\n",
    "        epsilon = 1e-4\n",
    "        spec_db = np.array(20 * np.log10(spec + epsilon))\n",
    "        spects.append((spec_db, audio[1]))\n",
    "    return spects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory containing audio files\n",
    "audio_dir = 'data/audioMNIST/data_OG_trimmed/'\n",
    "files = os.listdir(audio_dir)\n",
    "\n",
    "# Create output directory for the plots\n",
    "output_dir = \"comparison/spec_OG/\"\n",
    "if os.path.exists(output_dir):\n",
    "    # Remove all files in the output directory\n",
    "    for f in os.listdir(output_dir):\n",
    "        os.remove(os.path.join(output_dir, f))\n",
    "else:\n",
    "    # If the directory doesn't exist, create it\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load audio data\n",
    "audio_data = load_data(audio_dir)\n",
    "\n",
    "# Specify the desired padding length (change as needed)\n",
    "padding_length = 8000\n",
    "\n",
    "# Generate spectrograms\n",
    "for audio, name in audio_data:\n",
    "    if len(audio) > 8000:  # Skip audio files longer than 8000 samples\n",
    "        continue\n",
    "    \n",
    "    # Pad and compute the STFT\n",
    "    padded_audio = pad_signal(audio, padding_length)\n",
    "    spec = stft(padded_audio, frame_size=256, overlap=128)\n",
    "    \n",
    "    # Convert to decibels\n",
    "    epsilon = 1e-4\n",
    "    spec_db = np.array(20 * np.log10(spec + epsilon))\n",
    "    \n",
    "    # Create the time axis for the spectrogram\n",
    "    n_frames_spec = spec_db.shape[1]\n",
    "    time_spec = np.linspace(0, len(padded_audio) / 22050, n_frames_spec)  # Adjust sr if necessary\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 4))  # Set figure size\n",
    "    plt.imshow(spec_db, aspect='auto', origin='lower', extent=[0, len(padded_audio)/22050, 0, 11025], cmap='gray', interpolation='none')\n",
    "    plt.xlim([0, len(padded_audio) / 22050])\n",
    "    plt.title(f\"Spectrogram for {name} (Trimmed Original)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.colorbar(label=\"Magnitude (dB)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "\n",
    "    # Save the plot\n",
    "    plot_path = os.path.join(output_dir, f\"{name}.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()  # Close the figure to free up memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your helper functions here (pad_signal, load_data, trim_signals, pad_segment, stft, gen_spectgrams)\n",
    "\n",
    "# Directory containing audio files\n",
    "audio_dir = 'results_mat/reconstructed_results/'\n",
    "files = os.listdir(audio_dir)\n",
    "\n",
    "# Create output directory for the plots\n",
    "output_dir = \"comparison/spec_recon/\"\n",
    "if os.path.exists(output_dir):\n",
    "    # Remove all files in the output directory\n",
    "    for f in os.listdir(output_dir):\n",
    "        os.remove(os.path.join(output_dir, f))\n",
    "else:\n",
    "    # If the directory doesn't exist, create it\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load audio data\n",
    "audio_data = load_data(audio_dir)\n",
    "\n",
    "# Specify the desired padding length (change as needed)\n",
    "padding_length = 8000\n",
    "\n",
    "# Generate spectrograms\n",
    "for audio, name in audio_data:\n",
    "    if len(audio) > 8000:  # Skip audio files longer than 8000 samples\n",
    "        continue\n",
    "    \n",
    "    # Pad and compute the STFT\n",
    "    padded_audio = pad_signal(audio, padding_length)\n",
    "    spec = stft(padded_audio, frame_size=256, overlap=128)\n",
    "    \n",
    "    # Convert to decibels\n",
    "    epsilon = 1e-4\n",
    "    spec_db = np.array(20 * np.log10(spec + epsilon))\n",
    "    \n",
    "    # Create the time axis for the spectrogram\n",
    "    n_frames_spec = spec_db.shape[1]\n",
    "    time_spec = np.linspace(0, len(padded_audio) / 22050, n_frames_spec)  # Adjust sr if necessary\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 4))  # Set figure size\n",
    "    plt.imshow(spec_db, aspect='auto', origin='lower', extent=[0, len(padded_audio)/22050, 0, 11025], cmap='grey', interpolation='none')\n",
    "    plt.xlim([0, len(padded_audio) / 22050])\n",
    "    plt.title(f\"Spectrogram for {name.replace('.npy', '')} (Reconstructed)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.colorbar(label=\"Magnitude (dB)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "\n",
    "    # Save the plot\n",
    "    plot_path = os.path.join(output_dir, f\"{name.replace('.npy', '')}.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()  # Close the figure to free up memory\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time domain \n",
    "\n",
    "audio_dir = 'comparison/time_OG/'\n",
    "recon_dir = 'comparison/time_recon'\n",
    "\n",
    "output_dir_com_time = \"comparison/time_compare\"\n",
    "\n",
    "\n",
    "if os.path.exists(output_dir_com_time):\n",
    "    # Remove all files in the output directory\n",
    "    for f in os.listdir(output_dir_com_time):\n",
    "        os.remove(os.path.join(output_dir_com_time, f))\n",
    "else:\n",
    "    # If the directory doesn't exist, create it\n",
    "    os.makedirs(output_dir_com_time)\n",
    "\n",
    "files_com = os.listdir(recon_dir)\n",
    "\n",
    "\n",
    "for file in files_com:\n",
    "\n",
    "    # Open the images\n",
    "    OG_path = Image.open(f\"comparison/time_OG/{file}\")\n",
    "    recon_path = Image.open(f\"comparison/time_recon/{file}\")\n",
    "\n",
    "    # Get the size of each image\n",
    "    (width1, height1) = OG_path.size\n",
    "    (width2, height2) = recon_path.size\n",
    "\n",
    "    # Create a new image with a width equal to the sum of both images' widths\n",
    "    combined = Image.new('RGB', (width1 + width2, max(height1, height2)))\n",
    "\n",
    "    # Paste the images into the new combined image\n",
    "    combined.paste(OG_path, (0, 0))\n",
    "    combined.paste(recon_path, (width1, 0))\n",
    "\n",
    "    # Save or display the result\n",
    "    #combined.show()  # To display\n",
    "    combined.save(f'{output_dir_com_time}/{file}')  # To save\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spec compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spec \n",
    "\n",
    "audio_dir = 'comparison/spec_OG/'\n",
    "recon_dir = 'comparison/spec_recon'\n",
    "\n",
    "output_dir_com_spec = \"comparison/spec_compare\"\n",
    "\n",
    "\n",
    "if os.path.exists(output_dir_com_spec):\n",
    "    # Remove all files in the output directory\n",
    "    for f in os.listdir(output_dir_com_spec):\n",
    "        os.remove(os.path.join(output_dir_com_spec, f))\n",
    "else:\n",
    "    # If the directory doesn't exist, create it\n",
    "    os.makedirs(output_dir_com_spec)\n",
    "\n",
    "files_com = os.listdir(recon_dir)\n",
    "\n",
    "\n",
    "for file in files_com:\n",
    "\n",
    "    # Open the images\n",
    "    OG_path = Image.open(f\"comparison/spec_OG/{file}\")\n",
    "    recon_path = Image.open(f\"comparison/spec_recon/{file}\")\n",
    "\n",
    "    # Get the size of each image\n",
    "    (width1, height1) = OG_path.size\n",
    "    (width2, height2) = recon_path.size\n",
    "\n",
    "    # Create a new image with a width equal to the sum of both images' widths\n",
    "    combined = Image.new('RGB', (width1 + width2, max(height1, height2)))\n",
    "\n",
    "    # Paste the images into the new combined image\n",
    "    combined.paste(OG_path, (0, 0))\n",
    "    combined.paste(recon_path, (width1, 0))\n",
    "\n",
    "    # Save or display the result\n",
    "    #combined.show()  # To display\n",
    "    combined.save(f'{output_dir_com_spec}/{file}')  # To save\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not understand the audio in 4_yweweler_34.npy.wav.\n",
      "Could not understand the audio in 5_nicolas_6.npy.wav.\n",
      "Could not understand the audio in 3_lucas_20.npy.wav.\n",
      "Could not understand the audio in 7_nicolas_15.npy.wav.\n",
      "Could not understand the audio in 8_yweweler_7.npy.wav.\n",
      "Could not understand the audio in 0_lucas_3.npy.wav.\n",
      "Could not understand the audio in 2_lucas_47.npy.wav.\n"
     ]
    }
   ],
   "source": [
    "# Define the folder containing the audio files\n",
    "audio_folder = \"results_mat/reconstructed_results/\"\n",
    "\n",
    "# Initialize the recognizer\n",
    "recognizer = sound_rec.Recognizer()\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(audio_folder):\n",
    "    # Check if the file is a .wav file (you can adjust this if needed)\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(audio_folder, filename)\n",
    "        \n",
    "        # Load the audio data\n",
    "        audio_data, sample_rate = sf.read(file_path)\n",
    "        \n",
    "        # Save it as a temporary .wav file\n",
    "        temp_wav_path = \"temp_audio.wav\"\n",
    "        sf.write(temp_wav_path, audio_data, sample_rate)\n",
    "        \n",
    "        # Use the temporary audio file for recognition\n",
    "        with sound_rec.AudioFile(temp_wav_path) as source:\n",
    "            audio = recognizer.record(source)\n",
    "        \n",
    "        # Perform speech recognition using Google's Web Speech API (default method)\n",
    "        try:\n",
    "            transcription = recognizer.recognize_google(audio)\n",
    "            print(f\"Transcription for {filename}: {transcription}\")\n",
    "        except sound_rec.UnknownValueError:\n",
    "            print(f\"Could not understand the audio in {filename}.\")\n",
    "        except sound_rec.RequestError as e:\n",
    "            print(f\"API request error for {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
